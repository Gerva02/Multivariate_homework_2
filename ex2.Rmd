---
title: "Ex 2 PS2"
output: pdf_document
date: "2025-05-04"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 2
The dataset glass contains data on n = 214 single glass fragments. Each case has a measured refractive
index (RI) and composition (weight percent of oxides of Na, Mg, Al, Si, K, Ca, Ba and Fe). The composition
sums to around 100%; what is not anything else is sand. The fragments are classified as six types (variable
type). The classes are window float glass (WinF), window non float glass (WinNF), vehicle window glass (Veh),
containers (Con), tableware (Tabl) and vehicle headlamps (Head).
```{r warning=FALSE}
library(tidyverse)
library(MASS)
library(ellipse)
library(nnet)
library(class)
library(mclust)
```




```{r cars}
glass<-read.table("data/glass.txt",header=T)
glass$type<-factor(glass$type)
levels(glass$type)<-c("WinF","WinNF","Veh","Con","Tabl","Head")
table(glass$type)
```

```{r}
dim(glass)
```

```{r}
head(glass)
```

La matrice dei dati è composta da 214 osservazioni e 10 variabili, riportate di seguito.
The matrix *glass* has 214 rows and 10 columns, the 9 predictors are the the following
* RI: the refractive index, which is adimensional
* 8 Chemical elements, all express as percentages of oxides of: 
  * Na: Sodium
  * Mg: Magnesium
  * Al: Aluminium
  * Si: Silicon
  * K: Potassium
  * Ca: Calcium
  * Ba: Barium
  * Fe: Iron
  
* Type : is the type of glass, which is the  __target variable__. Which has 7 possible values.

  1. building_windows_float_processed
  2. building_windows_non_float_processed
  3. vehicle_windows_float_processed
  4. vehicle_windows_non_float_processed 
  5. containers
  6. tableware
  7. headlamps

The target variable is of course analysized as a factor is -r.
```{r}
glass %>% is.na() %>% sum()
```
Furthermore we check that there are no NAs in the dataset.

Before going on to the exercise we still need to do a little exploratory analysis of the data set. We start by plotting the relative frequency of each glass type
```{r}
#bar plot freq relative
glass %>%
  ggplot(aes(x = type, y = after_stat(count)/sum(after_stat(count)), fill = type)) + 
  geom_bar() +
  labs(title = "Relative Frequency of Classes",y = "Freq Rel")
```
Such graph carries the same information of the table printed before but makes much clearer that some classes like tableware and containers are under represented in the data set, of course for any discrimination function it will be harder to recognize those classes when other classes are much more prevalent. In fact we notice that the first two classes are about 65% of the data, such situation is generally referred to as unbalanced data (i.e. When some classes have significantly more observation than others), but since no class of glass is more important than others we do not apply any oversampling or undersampling techinque. 

### Point 1
\textbf{Point 1}
Use linear discriminant analysis to predict the glass type. Look at the first two discriminant directions:
what are the most important variables in separating the classes? Comment.

Before applying the LDA, we check wheter the assumption of the model is verified, namely we check that each variable conditioned on class is normally distributed (i.e. each variable is a mixture of Gaussians) and if the  $\Sigma_i = \Sigma\quad \forall i \in(1,\dots,6) $. We do this trough a violin plot which is a graph that represents each variable
```{r}
glass %>%
  gather(key = Measure, value = value, -type )  %>%
  ggplot(aes(x = type, y= value, color = Measure)) +
  geom_violin(trim = F)+ 
  geom_boxplot(width=0.1) + 
  facet_wrap( ~ Measure ,scales = "free", ncol =3)+
  labs(title = "Violin Plot Conditioned on Classes") 
```


We can see that none of the above conditons is respected neither normality , since univariate normaly is not verified it is useless to check multivariate normality.

We procede by fitting the model:
```{r}
lda.fit<-lda(glass$type ~ . ,data=glass)
lda.fit
```

These results are not interpretable beacuse the variable have different unit of measurment to get of such 

```{r}
diag(diag(cov(glass[,1:9])** (1/2))) %*% lda.fit$scaling 
```
LD1 rimane influenzata da Na-Si-Al-Ca (tutti negativi->valori bassi=LD1 alto)
LD2 rimane fortemente influenzata da Mg-Ca-Na-Si (tutti positivi->valori bassi=LD2 basso)


### Point 2

```{r}
lda.pred  <-predict(lda.fit,glass)
training_error <- mean(lda.pred$class != glass$type )
training_error
```
the training error is as such

let's check that our linear predictor predicts equally well all 

```{r}
lda.pred  <-predict(lda.fit,glass)
conf.mat<-table(predicted=lda.pred$class,true=glass$type)
conf.mat2<-addmargins(conf.mat)
conf.mat2
```




```{r}
conf.mat<-apply(conf.mat,2,function(x) x/sum(x))
conf.mat
diag(conf.mat)
```
prima abbiamo trovato che l'errore medio è 1-training.err:0.6728972. con è gia al limite con 7 giuste su 13, ma il peggio ovviamente è in in Veh dove ne ha azzeccate 0 su 13, anzi peggio, ne ha predictate 3 tutte e tre sbagliate e non ha trovato neanche una di quelle giuste


### Point 3
```{r}
cv.index <- read.csv("data/groupCV.txt",header = F)
glass$cv.index <- cv.index[,]
```



```{r}
errors <- rep(NA,10)
for (i in (1:10)){
  training_set <- glass %>% filter(cv.index != i) 
  test_set <- glass %>% filter(cv.index == i) 
  lda.fit.cv <-lda(training_set$type ~ . , data= training_set[,1:10])
  lda.pred.cv <- predict(lda.fit.cv,newdata = test_set[,1:10])
  errors[i]<-mean(lda.pred.cv$class != test_set$type )
}
mean(errors)
```
Using the cv we get a more accurate view of the error rate of our classifier since we leverage the law of large numbers 


```{r}
lookup<-c("black", "blue", "brown", "gray60",
"green3", "orange")
names(lookup)<-as.character(unique(glass$type))

```



```{r}
data.col<-lookup[glass$type]
means.hat.z<-aggregate(lda.pred$x,by=list(glass$type),FUN=mean)[,-1]
plot(LD2~LD1,xlim = c(0.0001, 4), 
     data=lda.pred$x[,1:2],asp=1,pch=16,col=data.col)
points(means.hat.z[,1],means.hat.z[,2],pch=21,bg=lookup,cex=1.2 )
```

Però guardando lo scatter ciò non ci sorprende(che il veh sia cosi difficile da sgamare). Blu-Nero e Brown sono dannatamente vicinissimi
Veh(Brown) è stato confuso 11 volte con WinF(nero) e 3 volte con WinNF (b)
ciò si ricollega con quanto dicevamo prima, qiesto non è un buon LDA

### Point 5


```{r}
errors.train.reduced<- rep(NA,5)
errors.test.reduced<- rep(NA,5)

for (j in (1:5)){
  errors.test<- rep(NA,10)

  for (i in (1:10)){
    training_set <- glass %>% filter(cv.index != i) 
    test_set <- glass %>% filter(cv.index == i) 
    
    lda.fit.cv <-lda(training_set$type ~ .  , data= training_set[,1:10])
    lda.pred.test.cv <- predict(lda.fit.cv,test_set[,1:10], dim = j )
    errors.test[i]<-mean(lda.pred.test.cv$class != test_set$type )

  }
  
  lda.pred<-predict(lda.fit,glass,dimen=j)
  errors.train.reduced[j]<-mean(lda.pred$class!=glass$type)
  errors.test.reduced[j]<-mean(errors.test)
}
errors.test.reduced
errors.train.reduced
```


```{r}
df <- data.frame(
  iter  = rep(seq_along(errors.train.reduced), 2),
  error = c(errors.train.reduced, errors.test.reduced),
  serie = rep(c("Errors train", "Errors test"), each = length(errors.train.reduced))
)

ggplot(df, aes(iter, error, colour = serie)) +
  geom_line(linewidth = 1) +
  labs(x = "Number of LDA", y = "Error",
       title = "Comparison Error Curves") +
  theme_bw()

```
We prefer classifier with 4 LDA because it has the least amount of test error


### Point 6



```{r}
library(e1071) 
library(caTools)
library(ggplot2)
errors <- rep(NA,10)
for (i in (1:10)){
  training_set <- glass %>% filter(cv.index != i) 
  test_set <- glass %>% filter(cv.index == i) 
  mod<-svm(training_set$type ~ . - cv.index,data=training_set)
  errors[i]<-mean(predict(mod,test_set) != test_set$type )
}
mean(errors)
```





